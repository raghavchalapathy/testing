\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\citation{phoha2002internet}
\citation{vigna2005host}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Applications of Deep Anomaly Detection}{15}{section.1.9}}
\newlabel{sec:applicationsOfDLAD}{{1.9}{15}{Applications of Deep Anomaly Detection}{section.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.1}Intrusion Detection}{15}{subsection.1.9.1}}
\newlabel{sec:intrusion_detection}{{1.9.1}{15}{Intrusion Detection}{subsection.1.9.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.1.1}Host-Based Intrusion Detection Systems (HIDS):}{15}{subsubsection.1.9.1.1}}
\citation{kim2016lstm}
\citation{chawla2018host}
\citation{chen2018henet}
\citation{sohi2018recurrent}
\citation{vinayakumar2017applying}
\citation{aghakhani2018detecting}
\citation{li2018anomaly}
\citation{gao2014intrusion}
\citation{peharz2018probabilistic}
\citation{umer2018two}
\citation{yu2017network}
\citation{thing2017ieee}
\citation{zolotukhin2016increasing}
\citation{cordero2016analyzing}
\citation{alrawashdeh2016toward}
\citation{tang2016deep}
\citation{lopez2017conditional}
\citation{al2018deep}
\citation{mirsky2018kitsune}
\citation{aygun2017network}
\citation{lin2018idsgan}
\citation{yin2018enhancing}
\citation{ring2018flow}
\citation{latah2018deep}
\citation{intrator2018mdgan}
\citation{matsubara2018anomaly}
\citation{nicolau2016hybrid}
\citation{rigaki2017adversarial}
\citation{yu2017network}
\citation{malaiya2018empirical}
\citation{kwon2018empirical}
\citation{gao2014intrusion}
\citation{staudemeyer2015applying}
\citation{naseer2018enhanced}
\citation{ucsdAnomalyDetect2017}
\citation{shiravi2012toward}
\citation{yu2017network}
\citation{adam2008robust}
\citation{yu2017network}
\citation{ucsdAnomalyDetect2017}
\citation{yin2017deep}
\citation{javaid2016deep}
\citation{tang2016deep}
\citation{yousefi2017autoencoder}
\citation{mohammadi2017new}
\citation{lopez2017conditional}
\citation{stolfo2000cost}
\citation{alrawashdeh2016toward}
\citation{van2017anomaly}
\citation{mohammadi2017new}
\citation{fontugne2010mawilab}
\citation{cordero2016analyzing}
\citation{jamkRGCE}
\citation{zolotukhin2016increasing}
\citation{creech2014semantic}
\citation{kim2016lstm}
\citation{chawla2018host}
\citation{ImmuneDatasets}
\citation{kim2016lstm}
\citation{chen2018henet}
\citation{abdallah2016fraud}
\citation{Lavion2018}
\citation{zhao2013fraud}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Classification of deep learning methods for Intrusion Detection.\relax }}{16}{figure.caption.23}}
\newlabel{fig:deepADforIDS}{{1.12}{16}{Classification of deep learning methods for Intrusion Detection.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.1.2}Network Intrusion Detection Systems (NIDS):}{16}{subsubsection.1.9.1.2}}
\newlabel{sec:intrusionDetect}{{1.9.1.2}{16}{Network Intrusion Detection Systems (NIDS):}{table.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.2}Fraud Detection}{16}{subsection.1.9.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used in HIDS  CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks  GRU: Gated Recurrent Unit, DNN : Deep Neural Networks  SPN: Sum Product Networks\relax }}{17}{table.caption.24}}
\newlabel{tab:HIDS}{{1.3}{17}{Examples of Deep learning anomaly detection Techniques Used in HIDS \\CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks \\GRU: Gated Recurrent Unit, DNN : Deep Neural Networks \\SPN: Sum Product Networks\relax }{table.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.4}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used in NIDS.  CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks  RNN: Recurrent Neural Networks, RBM : Restricted Boltzmann Machines  DCA: Dilated Convolution Autoencoders, CVAE : Convolutional Variational Autoencoder  AE: Autoencoders, SAE: Stacked Autoencoders , DBN : Deep Belief Network  GAN: Generative Adversarial Networks. \relax }}{17}{table.caption.25}}
\newlabel{tab:NIDS}{{1.4}{17}{Examples of Deep learning anomaly detection Techniques Used in NIDS. \\CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks \\RNN: Recurrent Neural Networks, RBM : Restricted Boltzmann Machines \\DCA: Dilated Convolution Autoencoders, CVAE : Convolutional Variational Autoencoder \\AE: Autoencoders, SAE: Stacked Autoencoders , DBN : Deep Belief Network \\GAN: Generative Adversarial Networks. \relax }{table.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.5}{\ignorespaces Datasets Used in Intrusion Detection \relax }}{18}{table.caption.26}}
\newlabel{tab:IDSDataset}{{1.5}{18}{Datasets Used in Intrusion Detection \relax }{table.caption.26}{}}
\citation{sorournejad2016survey}
\citation{zhou2018state}
\citation{suganya2015survey}
\citation{schreyer2017detection}
\citation{wedge2017solving}
\citation{paula2016deep}
\citation{renstrom2018fraud}
\citation{kazemi2017using}
\citation{zheng2018one}
\citation{pumsirirat2018credit}
\citation{pumsirirat2018credit}
\citation{seeja2014fraudminer}
\citation{sweers2018autoencoding}
\citation{fiore2017using}
\citation{choi2018generative}
\citation{dorronsoro1997neural}
\citation{gomez2018end}
\citation{wiese2009credit}
\citation{jurgovsky2018sequence}
\citation{heryadi2017learning}
\citation{ando2016detecting}
\citation{wang2017session}
\citation{alowais2012credit}
\citation{amarasinghe2018critical}
\citation{abroyan2017neural}
\citation{lp2018transaction}
\citation{shen2007application}
\citation{chouiekh2018convnets}
\citation{abroyan2017convolutional}
\citation{fu2016credit}
\citation{lu2017deep}
\citation{wang2018credit}
\citation{abroyan2017neural}
\citation{zhang2018model}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Fraud detection across various application domains.\relax }}{19}{figure.caption.27}}
\newlabel{fig:AerasOfFraud}{{1.13}{19}{Fraud detection across various application domains.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.2.1}Banking fraud:}{19}{subsubsection.1.9.2.1}}
\citation{chouiekh2018convnets}
\citation{alsheikh2016mobile}
\citation{badhe2017click}
\citation{akhter2012detecting}
\citation{jain2017perspective}
\citation{zheng2018generative}
\citation{joudaki2015using}
\citation{roy2017detecting}
\@writefile{lot}{\contentsline {table}{\numberline {1.6}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used for credit card fraud detection.  AE: Autoencoders, LSTM : Long Short Term Memory Networks  RBM: Restricted Botlzmann Machines, DNN : Deep Neural Networks  GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks  CNN: Convolutional Neural Networks,VAE: Variational Autoencoders  GAN: Generative Adversarial Networks\relax }}{20}{table.caption.28}}
\newlabel{tab:creditfraudDetect}{{1.6}{20}{Examples of Deep learning anomaly detection Techniques Used for credit card fraud detection. \\AE: Autoencoders, LSTM : Long Short Term Memory Networks \\RBM: Restricted Botlzmann Machines, DNN : Deep Neural Networks \\GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks \\CNN: Convolutional Neural Networks,VAE: Variational Autoencoders \\GAN: Generative Adversarial Networks\relax }{table.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.2.2}Mobile cellular network fraud:}{20}{subsubsection.1.9.2.2}}
\citation{viaene2005auto}
\citation{fajardo2018vos}
\citation{fiore2017using}
\citation{choi2018generative}
\citation{keung2009neural}
\citation{shen2007application}
\citation{zhang2018model}
\citation{bauder2017medicare}
\citation{lasaga2018deep}
\citation{ghasedi2018semi}
\citation{finlayson2018adversarial}
\citation{esteva2017dermatologist}
\citation{ye2017survey}
\@writefile{lot}{\contentsline {table}{\numberline {1.7}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used for mobile cellular network fraud detection.  CNN: convolution neural networks,DBN: Deep Belief Networks  SAE: Stacked Autoencoders, DNN : Deep neural networks  GAN: Generative Adversarial Networks \relax }}{21}{table.caption.29}}
\newlabel{tab:mobilefraudDetect}{{1.7}{21}{Examples of Deep learning anomaly detection Techniques Used for mobile cellular network fraud detection. \\CNN: convolution neural networks,DBN: Deep Belief Networks \\SAE: Stacked Autoencoders, DNN : Deep neural networks \\GAN: Generative Adversarial Networks \relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.2.3}Insurance fraud:}{21}{subsubsection.1.9.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.2.4}Health insurance fraud:}{21}{subsubsection.1.9.2.4}}
\newlabel{sec:fraudDetection}{{1.9.2.4}{21}{Health insurance fraud:}{table.caption.31}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.8}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used for insurance fraud detection.  DBN: Deep Belief Networks, DNN : Deep Neural Networks  CNN: Convolutional Neural Networks,VAE: Variational Autoencoders  GAN: Generative Adversarial Networks\relax }}{22}{table.caption.30}}
\newlabel{tab:insurancefraudDetect}{{1.8}{22}{Examples of Deep learning anomaly detection Techniques Used for insurance fraud detection. \\DBN: Deep Belief Networks, DNN : Deep Neural Networks \\CNN: Convolutional Neural Networks,VAE: Variational Autoencoders \\GAN: Generative Adversarial Networks\relax }{table.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.9}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used for health care fraud detection.  RBM: Restricted Botlzmann Machines, GAN: Generative Adversarial Networks\relax }}{22}{table.caption.31}}
\newlabel{tab:healthcarefraudDetect}{{1.9}{22}{Examples of Deep learning anomaly detection Techniques Used for health care fraud detection. \\RBM: Restricted Botlzmann Machines, GAN: Generative Adversarial Networks\relax }{table.caption.31}{}}
\citation{yousefi2017autoencoder}
\citation{hardy2016dl4md}
\citation{yousefi2017autoencoder}
\citation{de2018malware}
\citation{sewak2018investigation}
\citation{kebede2017classification}
\citation{de2018malware}
\citation{david2015deepsign}
\citation{cakir2018malware}
\citation{silva2018improving}
\citation{kolosnjaji2018adversarial}
\citation{suciu2018exploring}
\citation{srisakaokul2018muldef}
\citation{srisakaokul2018muldef}
\citation{king2018artificial}
\citation{huang2017r2}
\citation{guo2017malware}
\citation{abdelsalam2018malware}
\citation{raff2017malware}
\citation{karbab2018maldozer}
\citation{martinelli2017evaluating}
\citation{mclaughlin2017deep}
\citation{gibert2018using}
\citation{kolosnjaji2017empowering}
\citation{rosenberg2018end}
\citation{wang2017adversary}
\citation{david2015deepsign}
\citation{yang2016application}
\citation{ding2016application}
\citation{yuxin2017malware}
\citation{selvaganapathy2018deep}
\citation{yuxin2017malware}
\citation{hou2017deep}
\citation{tobiyama2016malware}
\citation{hu2017black}
\citation{tobiyama2018method}
\citation{passalislong}
\citation{le2018deep}
\citation{wang2017adversary}
\citation{kim2018zero}
\citation{wang2018effective}
\citation{li2015hybrid}
\citation{haddadpajouh2018deep}
\citation{min2017deep}
\citation{cao2018deep}
\citation{zhao2016deep}
\citation{khan2018review}
\citation{gugulothusparse}
\citation{amarasinghe2018toward}
\citation{choi2018doctor}
\citation{wang2016research}
\citation{cowton2018combined}
\citation{sato2018primitive}
\citation{turner2014deep}
\citation{sharma2016abnormality}
\citation{wulsin2010semi}
\citation{ma2018unsupervised}
\citation{zhang2016automatic}
\citation{wulsin2011modeling}
\citation{wu2015adaptive}
\citation{liao2016enhanced}
\citation{xu2018unsupervised}
\citation{lu2018anomaly}
\citation{ghasedi2018semi}
\citation{chen2018unsupervised}
\citation{yang2018toward}
\citation{jagannatha2016bidirectional}
\citation{cowton2018combined}
\citation{o2016recurrent}
\citation{latif2018phonocardiographic}
\citation{zhang2018time}
\citation{chauhan2015anomaly}
\citation{gugulothusparse}
\citation{amarasinghe2018toward}
\citation{schmidt2018artificial}
\citation{esteva2017dermatologist}
\citation{wang2016research}
\citation{iakovidis2018detecting}
\citation{song2017hybrid}
\@writefile{lot}{\contentsline {table}{\numberline {1.10}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used for malware detection.  AE: Autoencoders, LSTM : Long Short Term Memory Networks  RBM: Restricted Botlzmann Machines, DNN : Deep Neural Networks  GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks  CNN: Convolutional Neural Networks,VAE: Variational Autoencoders  GAN: Generative Adversarial Networks,CNN-BiLSTM: CNN- Bidirectional LSTM\relax }}{23}{table.caption.32}}
\newlabel{tab:malwareDetect}{{1.10}{23}{Examples of Deep learning anomaly detection Techniques Used for malware detection. \\AE: Autoencoders, LSTM : Long Short Term Memory Networks \\RBM: Restricted Botlzmann Machines, DNN : Deep Neural Networks \\GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks \\CNN: Convolutional Neural Networks,VAE: Variational Autoencoders \\GAN: Generative Adversarial Networks,CNN-BiLSTM: CNN- Bidirectional LSTM\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.3}Malware Detection}{23}{subsection.1.9.3}}
\newlabel{sec:malwareDetection}{{1.9.3}{23}{Malware Detection}{table.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.4}Medical Anomaly Detection:}{23}{subsection.1.9.4}}
\newlabel{sec:medical_anomaly_detection}{{1.9.4}{23}{Medical Anomaly Detection:}{subsection.1.9.4}{}}
\citation{savage2014anomaly}
\citation{anand2017anomaly}
\citation{yu2016survey}
\citation{cao2018automatic}
\citation{yu2016survey}
\citation{liu2017social}
\@writefile{lot}{\contentsline {table}{\numberline {1.11}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used for medical anomaly detection.  AE: Autoencoders, LSTM : Long Short Term Memory Networks  GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks  CNN: Convolutional Neural Networks,VAE: Variational Autoencoders  GAN: Generative Adversarial Networks, KNN: K-nearest neighbours  RBM: Restricted Boltzmann Machines.\relax }}{24}{table.caption.33}}
\newlabel{tab:medicalanomalyDetect}{{1.11}{24}{Examples of Deep learning anomaly detection Techniques Used for medical anomaly detection. \\AE: Autoencoders, LSTM : Long Short Term Memory Networks \\GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks \\CNN: Convolutional Neural Networks,VAE: Variational Autoencoders \\GAN: Generative Adversarial Networks, KNN: K-nearest neighbours \\RBM: Restricted Boltzmann Machines.\relax }{table.caption.33}{}}
\newlabel{sec:medicalAnomalyDetect}{{1.9.4}{24}{Medical Anomaly Detection:}{table.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.5}Deep learning for Anomaly detection in Social Networks}{24}{subsection.1.9.5}}
\citation{zhang2017detecting}
\citation{castellini2017fake}
\citation{sun2018detecting}
\citation{shu2017doc}
\citation{yang2018anomaly}
\citation{li2017detecting}
\citation{wei2017new}
\citation{memon2008log}
\citation{hochreiter1997long}
\citation{brown2018recurrent}
\citation{tuor2017deep}
\citation{das2018desh}
\citation{malhotra2015long}
\citation{du2017deeplog}
\citation{andrews2016detecting}
\citation{sakurada2014anomaly}
\citation{nolle2018analyzing}
\citation{nolle2016unsupervised}
\citation{grover2018anomaly}
\citation{wolpher2018anomaly}
\citation{brown2018recurrent}
\citation{zhang2018role}
\citation{nanduri2016anomaly}
\citation{fengming2017anomaly}
\citation{marchi2015non}
\citation{nolle2016unsupervised}
\citation{lu2018detecting}
\citation{yuan2018insider}
\citation{racki2018compact}
\citation{zhou2016spatial}
\citation{gorokhov2017convolutional}
\citation{liao2017deep}
\citation{cheng2017deep}
\citation{zhang2018alphamex}
\citation{mohammadi2018deep}
\@writefile{lot}{\contentsline {table}{\numberline {1.12}{\ignorespaces Examples of Deep learning anomaly detection techniques used to detect anomalies in social network.  CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks  AE: Autoencoders, DAE: Denoising Autoencoders  SVM : Support Vector Machines., DNN : Deep Neural Network \relax }}{25}{table.caption.34}}
\newlabel{tab:socialNetworkAnomalyDetect}{{1.12}{25}{Examples of Deep learning anomaly detection techniques used to detect anomalies in social network. \\CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks \\AE: Autoencoders, DAE: Denoising Autoencoders \\SVM : Support Vector Machines., DNN : Deep Neural Network \relax }{table.caption.34}{}}
\newlabel{sec:socialNetworks}{{1.9.5}{25}{Deep learning for Anomaly detection in Social Networks}{table.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.6}Log Anomaly Detection:}{25}{subsection.1.9.6}}
\newlabel{sec:logAnomaly}{{1.9.6}{25}{Log Anomaly Detection:}{table.caption.35}{}}
\citation{luo2018distributed}
\citation{mohammadi2018neural}
\citation{kakanakova2017outlier}
\citation{zhang2018lstm}
\citation{mudassar2018unsupervised}
\citation{ramotsoela2018survey}
\citation{marti2015anomaly}
\citation{atha2018evaluation}
\citation{de2018automatic}
\citation{wang2018residential}
\@writefile{lot}{\contentsline {table}{\numberline {1.13}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used in system logs.  CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks  GRU: Gated Recurrent Unit, DNN : Deep Neural Networks  AE: Autoencoders, DAE: Denoising Autoencoders\relax }}{26}{table.caption.35}}
\newlabel{tab:logAnomalyDetect}{{1.13}{26}{Examples of Deep learning anomaly detection Techniques Used in system logs. \\CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks \\GRU: Gated Recurrent Unit, DNN : Deep Neural Networks \\AE: Autoencoders, DAE: Denoising Autoencoders\relax }{table.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.7}Internet of things (IoT) Big Data Anomaly Detection}{26}{subsection.1.9.7}}
\newlabel{sec:iotBigDataAnomaly}{{1.9.7}{26}{Internet of things (IoT) Big Data Anomaly Detection}{table.caption.36}{}}
\citation{inoue2017anomaly}
\citation{thi2017one}
\citation{kravchik2018detecting}
\citation{huang2018deep}
\citation{park2018lired}
\citation{chang2018review}
\citation{yuan2015distributed}
\citation{araya2017ensemble}
\citation{qu2017detection}
\citation{sakurada2014anomaly}
\citation{bhattad2018detecting}
\citation{lodhi2017power}
\citation{faghih2016deep}
\citation{christiansen2016deepanomaly}
\citation{lee2016convolutional}
\citation{faghih2016deep}
\citation{dong2016camera}
\citation{nanduri2016anomaly}
\citation{fuentes2017robust}
\citation{huang2018deep}
\citation{chang2018review}
\citation{yan2015accurate}
\citation{luo2017gas}
\citation{dai2017cleaning}
\citation{banjanovic2017neural}
\citation{thi2017one}
\citation{inoue2017anomaly}
\citation{fawaz2018deep}
\citation{langkvist2014review}
\citation{gamboa2017deep}
\citation{lu2017unsupervised}
\citation{buda2018deepad}
\@writefile{lot}{\contentsline {table}{\numberline {1.14}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used in Internet of things (IoT) Big Data Anomaly Detection.   AE: Autoencoders, LSTM : Long Short Term Memory Networks   DBN : Deep Belief Networks.\relax }}{27}{table.caption.36}}
\newlabel{tab:iotBigDataAnomalyDetect}{{1.14}{27}{Examples of Deep learning anomaly detection Techniques Used in Internet of things (IoT) Big Data Anomaly Detection. \\ AE: Autoencoders, LSTM : Long Short Term Memory Networks \\ DBN : Deep Belief Networks.\relax }{table.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.8}Industrial Anomalies Detection}{27}{subsection.1.9.8}}
\newlabel{sec:industrialDamageDetect}{{1.9.8}{27}{Industrial Anomalies Detection}{table.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.9}Anomaly Detection in Time Series }{27}{subsection.1.9.9}}
\newlabel{sec:timeseriesAD}{{1.9.9}{27}{Anomaly Detection in Time Series }{subsection.1.9.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.15}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used in industrial operations.  CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks  GRU: Gated Recurrent Unit, DNN : Deep Neural Networks  AE: Autoencoders, DAE: Denoising Autoencoders, SVM: Support Vector Machines  SDAE: Stacked Denoising Autoencoders, RNN : Recurrent Neural Networks.\relax }}{28}{table.caption.37}}
\newlabel{tab:industrialDamageDetect}{{1.15}{28}{Examples of Deep learning anomaly detection Techniques Used in industrial operations. \\CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks \\GRU: Gated Recurrent Unit, DNN : Deep Neural Networks \\AE: Autoencoders, DAE: Denoising Autoencoders, SVM: Support Vector Machines \\SDAE: Stacked Denoising Autoencoders, RNN : Recurrent Neural Networks.\relax }{table.caption.37}{}}
\citation{shipmon2017time}
\citation{hundman2018detecting}
\citation{zhu2017deep}
\citation{hundman2018detecting}
\citation{malhotra2015long}
\citation{chauhan2015anomaly}
\citation{assendorp2017deep}
\citation{buda2018deepad}
\citation{ahmad2017unsupervised}
\citation{malhotra2016lstm}
\citation{bontemps2016collective}
\citation{taylor2016anomaly}
\citation{cheng2016ms}
\citation{loganathan2018sequence}
\citation{chauhan2015anomaly}
\citation{malhotra2015long}
\citation{gorokhov2017convolutional}
\citation{Dominique}
\citation{kieu2018outlier}
\citation{cowton2018combined}
\citation{malhotra2016multi}
\citation{malhotra2016lstm}
\citation{filonov2016multivariate}
\citation{sugimoto2018deep}
\citation{oh2018residual}
\citation{ebrahimzadehmulti}
\citation{wielgosz2017recurrent}
\citation{saurav2018online}
\citation{wielgosz2018model}
\citation{guo2016robust}
\citation{kanarachos2017detecting}
\citation{dumodeling}
\citation{gorokhov2017convolutional}
\citation{napoletano2018anomaly}
\citation{shanmugam2018jiffy}
\citation{medel2016anomaly}
\citation{park2018multimodal}
\citation{solch2016variational}
\citation{amarasinghe2018toward}
\citation{li2018anomaly}
\citation{zenati2018efficient}
\citation{lim2018doping}
\citation{laptevanogen}
\citation{kiran2018overview}
\citation{chong2015modeling}
\citation{boghossian2005challenges}
\@writefile{lot}{\contentsline {table}{\numberline {1.16}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used in time series data.  CNN: Convolution Neural Networks, GAN: Generative Adversarial networks,LSTM : Long Short Term Memory Networks  GRU: Gated Recurrent Unit, DNN : Deep Neural Networks,  AE: Autoencoders, DAE: Denoising Autoencoders, VAE: Variational Autoencoder   SDAE: Stacked Denoising Autoencoders\relax }}{29}{table.caption.38}}
\newlabel{tab:sensorAnomalyDetect}{{1.16}{29}{Examples of Deep learning anomaly detection Techniques Used in time series data. \\CNN: Convolution Neural Networks, GAN: Generative Adversarial networks,LSTM : Long Short Term Memory Networks \\GRU: Gated Recurrent Unit, DNN : Deep Neural Networks, \\AE: Autoencoders, DAE: Denoising Autoencoders, VAE: Variational Autoencoder \\ SDAE: Stacked Denoising Autoencoders\relax }{table.caption.38}{}}
\newlabel{sec:sensorNetworkAnomaly}{{1.9.9}{29}{Anomaly Detection in Time Series }{table.caption.38}{}}
\citation{dong2016camera}
\citation{andrewsaanomaly}
\citation{sabokrou2016fully}
\citation{sabokrou2017deep}
\citation{munawar2017spatio}
\citation{li2017transferred}
\citation{qiao2017abnormal}
\citation{tripathi2018convolutional}
\citation{nogas2018deepfall}
\citation{christiansen2016deepanomaly}
\citation{li2017transferred}
\citation{chong2017abnormal}
\citation{qiao2017abnormal}
\citation{khaleghi2018improved}
\citation{qiao2017abnormal}
\citation{yang2015unsupervised}
\citation{chen2015detecting}
\citation{gutoskidetection}
\citation{d2017autoencoder}
\citation{dotti2017unsupervised}
\citation{yang2015unsupervised}
\citation{chen2015detecting}
\citation{sabokrou2016video}
\citation{tran2017anomaly}
\citation{chen2015detecting}
\citation{d2017autoencoder}
\citation{hasan2016learning}
\citation{yang2015unsupervised}
\citation{cinelli2017anomaly}
\citation{gutoskidetection}
\citation{dotti2017unsupervised}
\citation{d2017autoencoder}
\citation{chianucci2016unsupervised}
\citation{munawar2017spatio}
\citation{medel2016anomaly}
\citation{luo2017remembering}
\citation{ben2018attentioned}
\citation{singh2017anomaly}
\citation{luo2017revisit}
\citation{zhou2015abnormal}
\citation{hu2016video}
\citation{chong2015modeling}
\citation{ravanbakhsh2017training}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.10}Video Surveillance}{30}{subsection.1.9.10}}
\newlabel{sec:videoSurvelliance}{{1.9.10}{30}{Video Surveillance}{table.caption.39}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.17}{\ignorespaces Examples of Deep learning anomaly detection Techniques Used in video surveillance.  CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks  RBM: Restricted Boltzmann Machine, DNN : Deep Neural Networks, CAE: Convolutional Autoencoders  AE: Autoencoders, DAE: Denoising Autoencoders, OCSVM: One class Support vector machines  SDAE: Stacked Denoising Autoencoders, STN : Spatial Transformer Networks \relax }}{31}{table.caption.39}}
\newlabel{tab:videoSurvellianceAnomalyDetect}{{1.17}{31}{Examples of Deep learning anomaly detection Techniques Used in video surveillance. \\CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks \\RBM: Restricted Boltzmann Machine, DNN : Deep Neural Networks, CAE: Convolutional Autoencoders \\AE: Autoencoders, DAE: Denoising Autoencoders, OCSVM: One class Support vector machines \\SDAE: Stacked Denoising Autoencoders, STN : Spatial Transformer Networks \relax }{table.caption.39}{}}
\@setckpt{Survey/applicationOfAD}{
\setcounter{page}{32}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{9}
\setcounter{subsection}{10}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{13}
\setcounter{table}{17}
\setcounter{parentequation}{0}
\setcounter{r@tfl@t}{0}
\setcounter{float@type}{4}
\setcounter{ContinuedFloat}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{47}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{mdf@globalstyle@cnt}{1}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{0}
\setcounter{@stackindex}{0}
\setcounter{ROWcellindex@}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{theorem}{0}
\setcounter{section@level}{0}
}
