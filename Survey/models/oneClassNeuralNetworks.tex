%!TEX root = ../../main.tex
\subsection{One class Neural Networks (OC-NN) for Anomaly Detection}
\label{sec:oneclassNN}
The One class Neural Networks  (OC-NN) combines the ability of deep networks to extract progressively rich representation of data alongwith the one-class objective, such as an hyperplane~\cite{chalapathy2018anomaly} or hypersphere ~\cite{ruff2018deep} to separate all the normal data points from the origin. The OC-NN approach is novel for the following crucial reason: data representation in the hidden layer as illustrated in
The experimental results in ~\cite{chalapathy2018anomaly,ruff2018deep} demonstrate that OC-NN can achieve comparable or better performance than existing state-of-the art methods for complex datasets, while having reasonable training and testing time compared to the existing methods.

\textbf{Assumptions : } \\
The OC-NN models proposed for anomaly detection rely on one the following assumptions to detect outliers:
\begin{itemize}
 \item  OC-NN models extracts the common factors of variation within the data distribution within the hidden layers of deep neural network to fit the model outputs into a hypersphere of minimum volume or construct a separating hyperplane.
  \item Performs combined representation learning and produces a outlier score for test data instance.
  \item Anomalous samples do not contain common factors of variation and hence hidden layers fails to capture the representations of outliers.
\end{itemize}

\textbf{Computational Complexity :} \\
The Computational complexity of an OC-NN model as against the  hybrid model includes only the complexity of deep network of choice ~\cite{saxe2011random}. OC-NN models do not require  data to be
stored for prediction, thus have very low memory complexity.However  it is evident that the OC-NN takes the longest time to train and is proportional to the dimension of the input space.

\textbf{Advantages and Disadvantages of OC-NN Techniques :}\\
The advantages of OC-NN deep anomaly detection techniques are as follows:
\begin{itemize}
\item  OC-NN  models jointly trains a deep neural network while optimizing a data-enclosing hypersphere or hyperplane in output space.
\item OC-NN~\cite{chalapathy2018anomaly} propose an alternating minimization algorithm for learning
the parameters of the OC-NN model. We observe that the subproblem of the OC-NN objective is equivalent to a solving a quantile selection problem which is well defined.
\end{itemize}
The significant disadvantages of OC-NN for anomaly detection are:
\begin{itemize}
\item Training times may be longer for high dimensional input data.
\item Model updates would also take longer time, given the change in input space.
\end{itemize}


