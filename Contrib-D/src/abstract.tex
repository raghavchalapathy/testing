% !TEX root=../main.tex

PCA is a classical statistical technique whose simplicity and maturity has seen it find widespread use for anomaly detection.
However, it is limited in this regard by being sensitive to gross perturbations of the input, and by seeking a linear subspace that captures normal behaviour.
The first issue has been dealt with by \emph{robust PCA}, a variant of PCA that explicitly allows for some data points to be arbitrarily corrupted;
however, this does not resolve the second issue,
and indeed introduces the new issue that one can no longer inductively find anomalies on a test set.
This paper addresses both issues in a single model, the \emph{robust autoencoder}.
This method learns a nonlinear subspace that captures the majority of data points, while allowing for some data to have arbitrary corruption.
The model is simple to train and leverages recent advances in the optimisation of deep neural networks.
Experiments on a range of real-world datasets highlight the model's effectiveness.

\keywords{anomaly detection, outlier detection, robust PCA, autoencoders, deep learning}
