%!TEX root = ../../main.tex
\subsection{Other Deep Anomaly Detection (DAD) Techniques}
This section explores, different deep anomaly detection techniques which are shown to be effective and promising,  we discuss the key idea behind those techniques, and their area of applicability.

\subsubsection{\textbf{Transfer Learning based anomaly detection :} }
Deep learning for long has been critized for the need to have enough data to produce good results.
Transfer learning relaxes this data dependence which motivates one to use transfer learning
to solve the problem of insufficient training data. ~\cite{litjens2017survey,pan2010survey} present the review on deep transfer learning approaches. Transfer learning is an important tool in machine learning to solve the basic problem of insufficient training data. It aims to transfer the knowledge from the source domain to the target domain by relaxing the assumption that the training and future data must be in the same feature space and have the same distribution. Deep transfer representation-learning has been explored by ~\cite{andrews2016transfer,vercruyssen2017transfer,li2012detecting,almajai2012anomaly,kumar2017transfer,liang2018transfer} and shown to produce very promising results. The open research questions using transfer learning for anomaly detection is , the degree of  transferability, that is to define how well features at that layer transfer from one task to another. Obtaining greater understanding of these open questions could be a valuble resource for improving deep anomaly detection performance.

\subsubsection{\textbf{Zero Shot learning based anomaly detection:}}
Zero shot learning (ZSL)  aims recognize objects never seen before within training set~\cite{romera2015embarrassingly}.
ZSL achieves this  in two phases: Firstly the  knowledge about the objects in natural language descriptions or attributes (commonly known as meta-data) is captured Secondly this knowledge is then used to classify instances among a new set of classes. This setting is important in the real world since one may not be able to obtain images of all the possible classes at training. The main challenge associated with this approach is the obtaining the meta-data about the data instances. However several approaches of using ZSl in anomaly and novelty detection are shown to produce state-of-the-art results ~\cite{mishra2017generative,,socher2013zero,xian2017zero,liu2017generalized,rivero2017grassmannian}.

\subsubsection{\textbf{Ensemble based anomaly detection:}}
 A notable issue with deep neural networks is that they are sensitive to noise and often
require large training data to perform robustly. In order to achieve robustness even in noisy data an idea to randomly vary on the connectivity architecture of the autoencoder to obtain
signicantly better performance. An autoencoder ensembles consisting of  various randomly connected autoencoders are experimented by  ~\cite{chen2017outlier} to achieve promising results on several bench-mark datasets. Similarly ~\cite{kim2016lstm} employ a novel ensemble method that combines  multiple thresholding classifiers into a single one unit , enabling it possible to recognize ‘highly normal’ sequences. The ensemble approaches are still an active area of research which has been shown to produce improved diversity, thus avoiding overfitting and reducing the training time.

\subsubsection{\textbf{Clustering based anomaly detection:}}
Several anomaly detection  algorithms based on clustering have been proposed in literature ~\cite{ester1996density}. Clustering involves grouping together similar patterns based on features extracted  detect new anomalies.  Deep learning enabled clustering approach anomaly detection utilizes word2vec ~\cite{mikolov2013efficient}  models to get the semantical presentations of normal data and anomalies. Finally, the features extracted are grouped to form clusters and detect outliers ~\cite{yuan2017deep}. Many works rely on variants of hybrid models with auto-encoders and use the encoder outputs as representations for clustering ~\cite{aytekin2018clustering,xie2016unsupervised,guo2017improved,xie2016unsupervised,guo2017deep,wang2016learning,mani2018scalable}. The time and space complexity grows linearly with number of classes to be clustered ~\cite{sreekanth2010generalized}, which renders the clustering based anomaly detection prohibitive for real-time practical applications. The dimensionality of the data is reduced by using the extracted features within the hidden layers of deep neural network which ensures scalability for complex and high dimensional datasets.


\subsubsection{\textbf{Deep Reinforcement Learning (DRL) based anomaly detection:}}
\label{reinforcementlearning},
Deep reinforcement learning (DRL) methods have attracted significant interest due to its ability to learn complex behaviors in high-dimensional data space. Efforts to detect anomalies using deep reinforcement learning have been proposed by ~\cite{de2017learning,rlanomaly}.
The DRL based anomaly detector  does not consider any assumption about the concept of the anomaly,  the detector identifies new anomalies by consistently enhancing its knowledge  through reward signals accumulated. DRL based anomaly detection is a very novel concept which  requires identification of research gap and its applications.

\subsubsection{\textbf{Statistical Techniques based anomaly detection: }}
Hilbert transform is statistical signal processing technique which derives the analytic representation of a real-valued signal. This property is leveraged by ~\cite{kanarachos2015anomaly} for real time detection of anomalies health related time series dataset and is shown to be a very promising technique. The algorithm is expressed as a combination of wavelet analysis, neural networks and Hilbert transform in a sequential manner.  Although the authors claim the real time detection of anomalies In the fourth comming years these statistical signal processing techniques have been rarely experimented due to the fact that the training phase can be computationally demanding and exprensive.

