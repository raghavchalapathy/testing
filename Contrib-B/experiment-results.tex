\subsection{Results and Analysis}
\label{sec:result_analysis}
 Table \ref{table3} shows the performance comparison between the employed bidirectional LSTM-CRF and state-of-the-art CE systems. As an overall note, the bidirectional LSTM-CRF have not reached the same accuracy as the top system, semi-supervised Markov HMM  \cite{de2011machine}. However, our approach has achieved the second-best score on 2010 i2b2/VA. These results seem interesting on the ground that the bidirectional LSTM-CRF provide CE without utilizing any manually-engineered features. Given that our system learn entirely from the data, it is also robust to any new concept or unseen words additions. In our current experimental setting about $20\%$ of tokens were either alpha-numeric or abbreviated strings whose Word2Vec or  Glove pretrained vector embeddings were not available. These special strings in text were randomly initialized with $d=300$ vector embeddings and input to bidirectional LSTM-CRF system. Subsequently the system was able to learn  meaningfull representations with remaining $80\%$ of pre-trained vector embeddings and produce comparable results to the state-of-the-art CE systems.


